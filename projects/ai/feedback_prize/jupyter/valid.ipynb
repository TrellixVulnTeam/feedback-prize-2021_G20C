{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import spacy\n",
    "import sys\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('..')\n",
    "import gezi\n",
    "from gezi import tqdm\n",
    "from src.eval import calc_f1\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from absl import flags\n",
    "FLAGS = flags.FLAGS\n",
    "from transformers import AutoTokenizer\n",
    "from src import config\n",
    "from src.model import Model\n",
    "from src.dataset import Dataset\n",
    "from src.util import get_preds\n",
    "import melt as mt\n",
    "import husky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = 'base.20211227-025600'\n",
    "mn = 'base.m2.20211227-113522'\n",
    "v = '0'\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| config.py:54 in init_()\n",
      "    FLAGS.backbone: '../input/allenai/longformer-base-4096'\n",
      "ic| config.py:54 in init_()\n",
      "    FLAGS.backbone: '../input/allenai/longformer-base-4096'\n",
      "ic| config.py:63 in init()\n",
      "    FLAGS.valid_files[:2]: ['../input/feedback-prize-2021/tfrecords/train/70.164.tfrec',\n",
      "                            '../input/feedback-prize-2021/tfrecords/train/90.164.tfrec']\n",
      "All model checkpoint layers were used when initializing TFLongformerModel.\n",
      "\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at ../input/allenai/longformer-base-4096.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n",
      "ic| model.py:30 in __init__()- num_classes: 8\n"
     ]
    }
   ],
   "source": [
    "model_dir = f'../working/offline/{v}/{mn}'\n",
    "argv = open(f'{model_dir}/command.txt').readline().strip().split()\n",
    "FLAGS(argv)\n",
    "config.init_()\n",
    "config.init()\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3c0ff597224b828753c1cb2aafebdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_num_records:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3119"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset(files=FLAGS.valid_files)\n",
    "num_insts = dataset.num_instances\n",
    "num_insts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.make_batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(next(iter(d))[0])\n",
    "model.load_weights(f'{model_dir}/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a35f1efe5ff468a8088c80030819099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "infer:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  strategy = mt.distributed.get_strategy()\n",
    "  with strategy.scope():   \n",
    "    res = model.infer(d, steps=dataset.num_steps, callbacks=[husky.TQDMProgressBar('infer')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.save(res, f'{model_dir}/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0662240fc4b465c4349360a9dfc6a6e2ea04641a433e7a5d8ebbabdd2e0b514"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
