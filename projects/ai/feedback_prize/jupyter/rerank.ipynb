{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'tensorflow.python.keras.layers.preprocessing'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import pymp \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "from IPython.display import display_html\n",
    "from itertools import chain, cycle\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('..')\n",
    "import gezi\n",
    "from gezi import tqdm\n",
    "from src.eval import *\n",
    "from src.util import *\n",
    "from src import config\n",
    "from src.visualize import *\n",
    "from src.decode import *\n",
    "pd.set_option('display.float_format', lambda x: '%.04f' % x)\n",
    "gezi.set_pandas_widder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.read_feather('../input/feedback-prize-2021/train_en.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = pd.read_feather('../input/feedback-prize-2021/train_flat_en.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>kfold</th>\n",
       "      <th>cluster</th>\n",
       "      <th>worker</th>\n",
       "      <th>part</th>\n",
       "      <th>para_type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens. [BR] [BR] A mesa is a naturally occuring rock formation, that is found on Mars and Earth. This \"face\" on mars only looks like a face because humans tend to see faces wherever we look, humans are obviously extremely social, which is why our brain is designed to recognize faces. [BR] [BR] Many conspiracy theorists believe that NASA is hiding life on Mars from the rest of the world. These people would be very wrong. If NASA found life on Mars, then they would get millions of people's attention. NASA's budget would increase drasticly, which means that their workers would get paid more. There is no good reason that NASA would hide life on Mars from the rest of the world. [BR] [BR] So, NASA is not hiding life on Mars from us, and they are not trying to trick us into thinking that the \"face\" on mars is just a mesa, because it actually is. NASA hiding life would be illogical, because if they found life on Mars, they would make a lot of money, and we all know that the people at NASA aren't illogical people.</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 2, 2, 1, 6, 7, 2, 4]</td>\n",
       "      <td>[0, 34, 69, 84, 117, 134, 154, 186]</td>\n",
       "      <td>[34, 69, 84, 117, 134, 154, 186, 251]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  kfold  cluster  worker  part                 para_type                                start                                    end\n",
       "0  0      0000D23A521A  Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens. [BR] [BR] A mesa is a naturally occuring rock formation, that is found on Mars and Earth. This \"face\" on mars only looks like a face because humans tend to see faces wherever we look, humans are obviously extremely social, which is why our brain is designed to recognize faces. [BR] [BR] Many conspiracy theorists believe that NASA is hiding life on Mars from the rest of the world. These people would be very wrong. If NASA found life on Mars, then they would get millions of people's attention. NASA's budget would increase drasticly, which means that their workers would get paid more. There is no good reason that NASA would hide life on Mars from the rest of the world. [BR] [BR] So, NASA is not hiding life on Mars from us, and they are not trying to trick us into thinking that the \"face\" on mars is just a mesa, because it actually is. NASA hiding life would be illogical, because if they found life on Mars, they would make a lot of money, and we all know that the people at NASA aren't illogical people.  0      7        10      2     [3, 2, 2, 1, 6, 7, 2, 4]  [0, 34, 69, 84, 117, 134, 154, 186]  [34, 69, 84, 117, 134, 154, 186, 251]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat['num_words'] = df_flat['text'].apply(lambda x: len(x.replace('[BR]', '\\n').split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>part</th>\n",
       "      <th>para_id</th>\n",
       "      <th>para_type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>start2</th>\n",
       "      <th>end2</th>\n",
       "      <th>para</th>\n",
       "      <th>text</th>\n",
       "      <th>pid</th>\n",
       "      <th>kfold</th>\n",
       "      <th>cluster</th>\n",
       "      <th>worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>Phones [BR] [BR]</td>\n",
       "      <td>Phones [BR] [BR] Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving. They are some really bad consequences when stuff happens when it comes to a phone. Some certain areas in the United States ban phones from class rooms just because of it. [BR] [BR] When people have phones, they know about certain apps that they have .Apps like Facebook Twitter Instagram and Snapchat. So like if a friend moves away and you want to be in contact you can still be in contact by posting videos or text messages. People always have different ways how to communicate with a phone. Phones have changed due to our generation. [BR] [BR] Driving is one of the way how to get around. People always be on their phones while doing it. Which can cause serious Problems. That's why there's a thing that's called no texting while driving. That's a really important thing to remember. Some people still do it because they think It's stupid. No matter what they do they still have to obey it because that's the only way how did he save. [BR] [BR] Sometimes on the news there is either an accident or a suicide. It might involve someone not looking where they're going or tweet that someone sent. It either injury or death. If a mysterious number says I'm going to kill you and they know where you live but you don't know the person's contact [BR] [BR] ,It makes you puzzled and make you start to freak out. Which can end up really badly. [BR] [BR] Phones are fine to use and it's also the best way to come over help. If you go through a problem and you can't find help you ,always have a phone there with you. Even though phones are used almost every day as long as you're safe it would come into use if you get into trouble. Make sure you do not be like this phone while you're in the middle of driving. The news always updated when people do something stupid around that involves their phones. The safest way is the best way to stay safe.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id  part  para_id  para_type  start  end  start2   end2              para                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text  pid  kfold  cluster  worker\n",
       "0  0      423A1CA112E2  13    0        0          0      1    0      3.0000  Phones [BR] [BR]  Phones [BR] [BR] Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving. They are some really bad consequences when stuff happens when it comes to a phone. Some certain areas in the United States ban phones from class rooms just because of it. [BR] [BR] When people have phones, they know about certain apps that they have .Apps like Facebook Twitter Instagram and Snapchat. So like if a friend moves away and you want to be in contact you can still be in contact by posting videos or text messages. People always have different ways how to communicate with a phone. Phones have changed due to our generation. [BR] [BR] Driving is one of the way how to get around. People always be on their phones while doing it. Which can cause serious Problems. That's why there's a thing that's called no texting while driving. That's a really important thing to remember. Some people still do it because they think It's stupid. No matter what they do they still have to obey it because that's the only way how did he save. [BR] [BR] Sometimes on the news there is either an accident or a suicide. It might involve someone not looking where they're going or tweet that someone sent. It either injury or death. If a mysterious number says I'm going to kill you and they know where you live but you don't know the person's contact [BR] [BR] ,It makes you puzzled and make you start to freak out. Which can end up really badly. [BR] [BR] Phones are fine to use and it's also the best way to come over help. If you go through a problem and you can't find help you ,always have a phone there with you. Even though phones are used almost every day as long as you're safe it would come into use if you get into trouble. Make sure you do not be like this phone while you're in the middle of driving. The news always updated when people do something stupid around that involves their phones. The safest way is the best way to stay safe.  0    2      8        67    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 47\n",
    "votes = gezi.read_pickle(f'../working/offline/{v}/votes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0035eadf2e1f4fa0a751d208c9bbecec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = Manager().dict()\n",
    "with pymp.Parallel(len(votes)) as p:\n",
    "  for i in p.range(len(votes)):\n",
    "    vote = votes[i]\n",
    "    fes = []\n",
    "    for id in tqdm(vote, total=len(vote)):\n",
    "      fe = {}\n",
    "      fe['id'] = id\n",
    "      fe['model'] = i\n",
    "      gt = get_gt_dict(df_gt, id)\n",
    "      num_gts = 0\n",
    "      for key in gt:\n",
    "        num_gts += len(gt[key])\n",
    "      fe['num_gts'] = num_gts\n",
    "      res_list = vote[id]\n",
    "      pred = list_to_dict(res_list)\n",
    "      fe['score'] = essay_f1(gt, pred, return_dict=False)\n",
    "      fe['cls'] = []\n",
    "      fe['len'] = []\n",
    "      fe['sep_prob'] = []\n",
    "      fe['token_logits'] = []\n",
    "      fe['token_probs'] = []\n",
    "      for res in res_list:\n",
    "        fe['cls'].append(res['cls'])\n",
    "        fe['len'].append(res['len'])\n",
    "        fe['sep_prob'].append(res['sep_prob'])\n",
    "        fe['token_logits'].append(res['token_logits'])\n",
    "        fe['token_probs'].append(res['token_prob'])\n",
    "      fe['num_paras'] = len(fe['cls'])\n",
    "      fes.append(fe)\n",
    "    d = pd.DataFrame(fes)\n",
    "    dfs[i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.710594286387137"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6319851517440416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[1].score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975040916905079"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[13].score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df for x, df in dfs.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>num_gts</th>\n",
       "      <th>score</th>\n",
       "      <th>cls</th>\n",
       "      <th>len</th>\n",
       "      <th>sep_prob</th>\n",
       "      <th>token_logits</th>\n",
       "      <th>token_probs</th>\n",
       "      <th>num_paras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>[5, 3, 1, 2, 1, 2, 6, 7, 2, 4]</td>\n",
       "      <td>[21, 13, 17, 18, 15, 33, 17, 20, 32, 65]</td>\n",
       "      <td>[0.9144795269866627, 0.8629530995247405, 0.7717764474869726, 0.9963936547909024, 0.8864285333444537, 0.9983718313682012, 0.9548764752687496, 0.1772727876030648, 0.9980646076789675, 1.0]</td>\n",
       "      <td>[[0.3779178722983315, -1.6021377472650438, -2.4511854364758445, 2.75136205128261, -3.1190939176650274, 6.784086636134556, -0.9309209727105641, -2.6760353360857283], [-1.6985660974796002, 1.3281200298896203, 0.03521042001935152, 6.736131227933443, -3.4585539377652683, 1.5385815455363347, -3.3237388684199405, -1.8013806343078613], [-0.16776051306549242, 3.889273489222807, 3.2884954003726734, 2.2212097434436573, -4.279685974121094, -0.24686236854861765, -3.0662520633024326, -2.8563820053549374], [1.5465700692600675, 3.2572935157352023, 3.8807343509462147, 1.8826661441061232, -3.5286709202660456, -2.633055461777581, -2.761381361219618, -3.0761695437961154], [1.3244357268015543, 6.355816173553467, 3.734326887130737, -1.7101484616597493, -2.9606508096059163, -3.9881274700164795, -1.8525549650192261, -2.0613436778386434], [1.1095339872620322, 3.738290700045499, 7.229684627417362, -2.82918381690979, -3.2120424834164707, -3.498941081942934, -1.910789020133741, -2.065453189792055], [-0.5392662996754927, 0.7079517175169552, 1.1538029488395243, -1.8988807411754833, -1.873082020703484, -2.3295224273906037, 7.562848175273222, -1.8861653594409717], [-1.647926214337349, 0.8645792812108993, 3.0301221292465925, -3.07043097615242, -2.8233571290969848, -3.802316415309906, -0.9449738070368767, 5.793924880027771], [-0.45701957686105743, 2.372330540791154, 5.448880508542061, -3.096696086227894, -3.3657204806804657, -4.503334306180477, -2.5151140093803406, 3.801049843430519], [-0.13664574153148212, -0.4811398635403468, -0.12540175573757062, -0.8136148671118113, 7.412513322096604, -4.16263709801894, -2.213939362305861, -1.7650066669170672]]</td>\n",
       "      <td>[[0.03597789997793094, 0.005123395518389092, 0.00224702301398622, 0.42297086540757856, 0.001066609953361114, 20.520644611116158, 0.009420556089135567, 0.0025490389234554627], [0.0032720686513563408, 0.05854620507546927, 0.015958014396855562, 12.846224753073002, 0.0005449907851375334, 0.07222312862718198, 0.0005797487451693214, 0.0026510906458286406], [0.28519296332364474, 9.504166573912471, 5.213210986863298, 1.8180320737127278, 0.002952158247614629, 0.15523266783210912, 0.009459256004472796, 0.01175332010366096], [0.989376424583566, 5.4623483627987115, 10.130964384154739, 1.3726218657404994, 0.006291668732230256, 0.015270996346196846, 0.013389219467480253, 0.009737078176575348], [0.09176379585072794, 13.878040284982458, 1.016766627728418, 0.004418548335143659, 0.0013258267631666202, 0.0004645488979186826, 0.00406948016590671, 0.003150887276260236], [0.0717915748991207, 0.9995492504482303, 31.918981517461567, 0.0014458678604222497, 0.0010122520787608272, 0.0007135357341694472, 0.003514443001647113, 0.002991558516089058], [0.005842686912692666, 0.018168354566757278, 0.02818684870528511, 0.001419479473214986, 0.0016176657160622018, 0.0009114656923993313, 16.9424111386575, 0.0014423602760861365], [0.013646131561206632, 0.15470972451665302, 2.7497039289186342, 0.0034723997795879378, 0.004219115012542414, 0.001559211399901754, 0.042943164047093765, 17.029746324764375], [0.10474905701341358, 2.0845112330929507, 23.703433758579003, 0.00632823985589014, 0.003615804257959434, 0.00119435774396254, 0.008660986905472817, 6.0875065625513445], [0.04347803737602476, 0.025488053400450152, 0.036846728252037234, 0.02030724286573219, 64.86146545968259, 0.0006594257016813699, 0.004743752472459133, 0.0070113002490211065]]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  model  num_gts  score                             cls                                       len                                                                                                                                                                                   sep_prob                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 token_logits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         token_probs  num_paras\n",
       "0  0000D23A521A  5      8       0.5238  [5, 3, 1, 2, 1, 2, 6, 7, 2, 4]  [21, 13, 17, 18, 15, 33, 17, 20, 32, 65]  [0.9144795269866627, 0.8629530995247405, 0.7717764474869726, 0.9963936547909024, 0.8864285333444537, 0.9983718313682012, 0.9548764752687496, 0.1772727876030648, 0.9980646076789675, 1.0]  [[0.3779178722983315, -1.6021377472650438, -2.4511854364758445, 2.75136205128261, -3.1190939176650274, 6.784086636134556, -0.9309209727105641, -2.6760353360857283], [-1.6985660974796002, 1.3281200298896203, 0.03521042001935152, 6.736131227933443, -3.4585539377652683, 1.5385815455363347, -3.3237388684199405, -1.8013806343078613], [-0.16776051306549242, 3.889273489222807, 3.2884954003726734, 2.2212097434436573, -4.279685974121094, -0.24686236854861765, -3.0662520633024326, -2.8563820053549374], [1.5465700692600675, 3.2572935157352023, 3.8807343509462147, 1.8826661441061232, -3.5286709202660456, -2.633055461777581, -2.761381361219618, -3.0761695437961154], [1.3244357268015543, 6.355816173553467, 3.734326887130737, -1.7101484616597493, -2.9606508096059163, -3.9881274700164795, -1.8525549650192261, -2.0613436778386434], [1.1095339872620322, 3.738290700045499, 7.229684627417362, -2.82918381690979, -3.2120424834164707, -3.498941081942934, -1.910789020133741, -2.065453189792055], [-0.5392662996754927, 0.7079517175169552, 1.1538029488395243, -1.8988807411754833, -1.873082020703484, -2.3295224273906037, 7.562848175273222, -1.8861653594409717], [-1.647926214337349, 0.8645792812108993, 3.0301221292465925, -3.07043097615242, -2.8233571290969848, -3.802316415309906, -0.9449738070368767, 5.793924880027771], [-0.45701957686105743, 2.372330540791154, 5.448880508542061, -3.096696086227894, -3.3657204806804657, -4.503334306180477, -2.5151140093803406, 3.801049843430519], [-0.13664574153148212, -0.4811398635403468, -0.12540175573757062, -0.8136148671118113, 7.412513322096604, -4.16263709801894, -2.213939362305861, -1.7650066669170672]]  [[0.03597789997793094, 0.005123395518389092, 0.00224702301398622, 0.42297086540757856, 0.001066609953361114, 20.520644611116158, 0.009420556089135567, 0.0025490389234554627], [0.0032720686513563408, 0.05854620507546927, 0.015958014396855562, 12.846224753073002, 0.0005449907851375334, 0.07222312862718198, 0.0005797487451693214, 0.0026510906458286406], [0.28519296332364474, 9.504166573912471, 5.213210986863298, 1.8180320737127278, 0.002952158247614629, 0.15523266783210912, 0.009459256004472796, 0.01175332010366096], [0.989376424583566, 5.4623483627987115, 10.130964384154739, 1.3726218657404994, 0.006291668732230256, 0.015270996346196846, 0.013389219467480253, 0.009737078176575348], [0.09176379585072794, 13.878040284982458, 1.016766627728418, 0.004418548335143659, 0.0013258267631666202, 0.0004645488979186826, 0.00406948016590671, 0.003150887276260236], [0.0717915748991207, 0.9995492504482303, 31.918981517461567, 0.0014458678604222497, 0.0010122520787608272, 0.0007135357341694472, 0.003514443001647113, 0.002991558516089058], [0.005842686912692666, 0.018168354566757278, 0.02818684870528511, 0.001419479473214986, 0.0016176657160622018, 0.0009114656923993313, 16.9424111386575, 0.0014423602760861365], [0.013646131561206632, 0.15470972451665302, 2.7497039289186342, 0.0034723997795879378, 0.004219115012542414, 0.001559211399901754, 0.042943164047093765, 17.029746324764375], [0.10474905701341358, 2.0845112330929507, 23.703433758579003, 0.00632823985589014, 0.003615804257959434, 0.00119435774396254, 0.008660986905472817, 6.0875065625513445], [0.04347803737602476, 0.025488053400450152, 0.036846728252037234, 0.02030724286573219, 64.86146545968259, 0.0006594257016813699, 0.004743752472459133, 0.0070113002490211065]]  10       "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_flat[['id', 'kfold']], on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7122536918869941"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.model==0) & (df.kfold==0)]['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_flat[['id', 'num_words']], on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feat(row):\n",
    "  fe = {}\n",
    "  fe['id'] = row['id']\n",
    "  fe['fold'] = row['kfold']\n",
    "  fe['score'] = row['score']\n",
    "  fe['model'] = row['model']\n",
    "  fe['num_paras'] = row['num_paras']\n",
    "  fe['num_words'] = row['num_words']\n",
    "  fe['num_gts'] = row['num_gts']\n",
    "  try:\n",
    "    sep_probs = np.array(row['sep_prob'][:-1])\n",
    "    fe['sep_prob_min'] = sep_probs.min()\n",
    "    fe['sep_prob_max'] = sep_probs.max()\n",
    "    fe['sep_prob_mean'] = sep_probs.mean()\n",
    "    classes = row['cls']\n",
    "    lens = np.array(row['len'])\n",
    "    fe['len_min'] = lens.min()\n",
    "    fe['len_max'] = lens.max()\n",
    "    fe['len_mean'] = lens.mean()\n",
    "    token_probs = gezi.softmax(row['token_probs'])\n",
    "    token_probs = np.array([prob[cls_] for cls_, prob in zip(classes, token_probs)])\n",
    "    fe['token_probs_min'] = token_probs.min()\n",
    "    fe['token_probs_max'] = token_probs.max()\n",
    "    fe['token_probs_mean'] = token_probs.mean()\n",
    "    \n",
    "    bigram_probs = []\n",
    "    for i in range(1, len(classes)):\n",
    "      a, b = classes[i - 1], classes[i]\n",
    "      a, b = id2dis[a], id2dis[b]\n",
    "      pair = f'{a}|{b}'\n",
    "      bigram_probs.append(bigrams.get(pair, 0) / unigrams[a])\n",
    "    bigram_probs = np.array(bigram_probs)\n",
    "    fe['bi_probs_min'] = bigram_probs.min()\n",
    "    fe['bi_probs_max'] = bigram_probs.max()\n",
    "    fe['bi_probs_mean'] = bigram_probs.mean()\n",
    "      \n",
    "  except Exception:\n",
    "    fe.update({\n",
    "      'sep_prob_min': 0,\n",
    "      'sep_prob_max': 0,\n",
    "      'sep_prob_mean': 0,\n",
    "      'len_min': 0,\n",
    "      'len_max': 0,\n",
    "      'len_mean': 0,     \n",
    "      'token_probs_min': 0,\n",
    "      'token_probs_max': 0,\n",
    "      'token_probs_mean': 0,\n",
    "      'bi_probs_min': 0,\n",
    "      'bi_probs_max': 0,\n",
    "      'bi_probs_mean': 0,\n",
    "    })\n",
    "  return fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cecb834b1145af82766668d4d65291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fes = []\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "  row = row._asdict()\n",
    "  fes.append(gen_feat(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dall = pd.DataFrame(fes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fold</th>\n",
       "      <th>score</th>\n",
       "      <th>model</th>\n",
       "      <th>num_paras</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_gts</th>\n",
       "      <th>sep_prob_min</th>\n",
       "      <th>sep_prob_max</th>\n",
       "      <th>sep_prob_mean</th>\n",
       "      <th>len_min</th>\n",
       "      <th>len_max</th>\n",
       "      <th>len_mean</th>\n",
       "      <th>token_probs_min</th>\n",
       "      <th>token_probs_max</th>\n",
       "      <th>token_probs_mean</th>\n",
       "      <th>bi_probs_min</th>\n",
       "      <th>bi_probs_max</th>\n",
       "      <th>bi_probs_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>25.1000</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.7723</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>25.1000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>27.8889</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>25.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.7014</td>\n",
       "      <td>15</td>\n",
       "      <td>65</td>\n",
       "      <td>27.8889</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265093</th>\n",
       "      <td>FEF334C14BAE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>294</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265094</th>\n",
       "      <td>FEF334C14BAE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>294</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5327</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.3629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265095</th>\n",
       "      <td>FEF334C14BAE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>294</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8455</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265096</th>\n",
       "      <td>FEF334C14BAE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>294</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5589</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265097</th>\n",
       "      <td>FEF334C14BAE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>294</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.3629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265098 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  fold  score  model  num_paras  num_words  num_gts  sep_prob_min  sep_prob_max  sep_prob_mean  len_min  len_max  len_mean  token_probs_min  token_probs_max  token_probs_mean  bi_probs_min  bi_probs_max  bi_probs_mean\n",
       "0       0000D23A521A  0    0.5238  5      10         251        8       0.1773        0.9984        0.8401          13       65      25.1000   0.9856           1.0000           0.9976            0.0736        0.6168        0.3648        \n",
       "1       0000D23A521A  0    0.4857  2      10         251        8       0.3232        0.9960        0.7723          13       65      25.1000   0.0002           1.0000           0.8999            0.0736        0.6168        0.3268        \n",
       "2       0000D23A521A  0    0.3810  4      9          251        8       0.4948        0.9975        0.8578          13       65      27.8889   0.7886           1.0000           0.9757            0.0736        0.5574        0.3093        \n",
       "3       0000D23A521A  0    0.4857  14     10         251        8       0.2536        0.9987        0.7987          13       65      25.1000   0.0000           1.0000           0.8683            0.0736        0.6168        0.3268        \n",
       "4       0000D23A521A  0    0.6286  15     9          251        8       0.0002        0.9951        0.7014          15       65      27.8889   0.0001           1.0000           0.8889            0.0736        0.6168        0.3293        \n",
       "...              ... ..       ...  ..    ..          ...       ..          ...           ...           ...          ..       ..          ...      ...              ...              ...               ...           ...           ...        \n",
       "265093  FEF334C14BAE  4    0.5714  12     8          294        7       0.7417        0.9996        0.8511          11       105     36.7500   0.9163           1.0000           0.9895            0.0736        0.6168        0.3341        \n",
       "265094  FEF334C14BAE  4    0.9000  16     7          294        7       0.5327        0.9992        0.8228          17       105     42.0000   0.6180           1.0000           0.9453            0.1385        0.5574        0.3629        \n",
       "265095  FEF334C14BAE  4    0.5714  7      8          294        7       0.6707        0.9995        0.8455          11       105     36.7500   0.9838           1.0000           0.9979            0.0736        0.6168        0.3341        \n",
       "265096  FEF334C14BAE  4    0.7500  0      8          294        7       0.5589        0.9980        0.7538          11       105     36.7500   0.6943           1.0000           0.9424            0.0000        0.5574        0.2908        \n",
       "265097  FEF334C14BAE  4    0.9000  9      7          294        7       0.6889        0.9983        0.8326          17       105     42.0000   0.9856           1.0000           0.9979            0.1385        0.5574        0.3629        \n",
       "\n",
       "[265098 rows x 19 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0833333333333333"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO FIX \n",
    "dall.score.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dall['score'] = dall.score.apply(lambda x: min(x, 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "dvalid = dall[dall.fold==fold]\n",
    "dtrain = dall[dall.fold!=fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'fold', 'score', 'model', 'num_paras', 'num_words', 'num_gts',\n",
       "       'sep_prob_min', 'sep_prob_max', 'sep_prob_mean', 'len_min', 'len_max',\n",
       "       'len_mean', 'token_probs_min', 'token_probs_max', 'token_probs_mean',\n",
       "       'bi_probs_min', 'bi_probs_max', 'bi_probs_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cols =  [\n",
    "              'num_words', \n",
    "              'num_paras',\n",
    "              'sep_prob_min',\n",
    "              'sep_prob_max',\n",
    "              'sep_prob_mean',\n",
    "              'len_min',\n",
    "              'len_max',\n",
    "              'len_mean', \n",
    "              'token_probs_min',\n",
    "              'token_probs_max',\n",
    "              'token_probs_mean',\n",
    "              'bi_probs_min',\n",
    "              'bi_probs_max',\n",
    "              'bi_probs_mean',\n",
    "        ]\n",
    "cat_cols = [\n",
    "            'model',\n",
    "            ]\n",
    "label_col = 'score'\n",
    "cols = reg_cols + cat_cols\n",
    "X_train = dtrain[cols]\n",
    "y_train = dtrain[[label_col]]\n",
    "X_valid = dvalid[cols]\n",
    "y_valid = dvalid[[label_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_boost_round = 2000\n",
    "params = {\n",
    "          # \"objective\": \"binary\",\n",
    "          # \"objective\": \"regression\" if label_col is 'score' else 'binary',\n",
    "          \"objective\": \"cross_entropy\",\n",
    "          \"metric\": \"auc\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"num_leaves\": 10,\n",
    "          \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.9,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": True,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 200,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"bagging_freq\": 5,\n",
    "          \"bagging_fraction\": 0.9,\n",
    "          \"num_trees\": 200,\n",
    "          \"subsample\": 0.9\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.535716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9\n",
      "[1]\tvalid_0's auc: 0.773638\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.77781\n",
      "[3]\tvalid_0's auc: 0.782886\n",
      "[4]\tvalid_0's auc: 0.797524\n",
      "[5]\tvalid_0's auc: 0.79264\n",
      "[6]\tvalid_0's auc: 0.793958\n",
      "[7]\tvalid_0's auc: 0.795454\n",
      "[8]\tvalid_0's auc: 0.806046\n",
      "[9]\tvalid_0's auc: 0.808276\n",
      "[10]\tvalid_0's auc: 0.81111\n",
      "[11]\tvalid_0's auc: 0.811396\n",
      "[12]\tvalid_0's auc: 0.812071\n",
      "[13]\tvalid_0's auc: 0.811871\n",
      "[14]\tvalid_0's auc: 0.813528\n",
      "[15]\tvalid_0's auc: 0.813483\n",
      "[16]\tvalid_0's auc: 0.812035\n",
      "[17]\tvalid_0's auc: 0.81349\n",
      "[18]\tvalid_0's auc: 0.812224\n",
      "[19]\tvalid_0's auc: 0.812664\n",
      "[20]\tvalid_0's auc: 0.813688\n",
      "[21]\tvalid_0's auc: 0.812877\n",
      "[22]\tvalid_0's auc: 0.814003\n",
      "[23]\tvalid_0's auc: 0.813573\n",
      "[24]\tvalid_0's auc: 0.814363\n",
      "[25]\tvalid_0's auc: 0.813699\n",
      "[26]\tvalid_0's auc: 0.81364\n",
      "[27]\tvalid_0's auc: 0.813735\n",
      "[28]\tvalid_0's auc: 0.814831\n",
      "[29]\tvalid_0's auc: 0.814191\n",
      "[30]\tvalid_0's auc: 0.814702\n",
      "[31]\tvalid_0's auc: 0.81401\n",
      "[32]\tvalid_0's auc: 0.81344\n",
      "[33]\tvalid_0's auc: 0.813735\n",
      "[34]\tvalid_0's auc: 0.812538\n",
      "[35]\tvalid_0's auc: 0.813269\n",
      "[36]\tvalid_0's auc: 0.813072\n",
      "[37]\tvalid_0's auc: 0.813511\n",
      "[38]\tvalid_0's auc: 0.813741\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.814831\n"
     ]
    }
   ],
   "source": [
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "bst = lgb.train(params, d_train, num_boost_round, valid_sets=d_valid, \n",
    "                categorical_feature=cat_cols,\n",
    "                verbose_eval=1,\n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 44),\n",
       " ('sep_prob_mean', 34),\n",
       " ('len_mean', 31),\n",
       " ('num_paras', 30),\n",
       " ('bi_probs_min', 27),\n",
       " ('num_words', 22),\n",
       " ('sep_prob_max', 21),\n",
       " ('token_probs_min', 19),\n",
       " ('len_min', 9),\n",
       " ('bi_probs_mean', 7),\n",
       " ('token_probs_mean', 4),\n",
       " ('bi_probs_max', 2),\n",
       " ('sep_prob_min', 1),\n",
       " ('len_max', 1),\n",
       " ('token_probs_max', 0)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(zip(bst.feature_name(), bst.feature_importance()))\n",
    "l.sort(key=lambda x: -x[1])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalid['pred'] = bst.predict(dvalid[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalid = dvalid.sort_values(['id', 'pred'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = dvalid.groupby('id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7022290862133234"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fold</th>\n",
       "      <th>score</th>\n",
       "      <th>model</th>\n",
       "      <th>num_paras</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_gts</th>\n",
       "      <th>sep_prob_min</th>\n",
       "      <th>sep_prob_max</th>\n",
       "      <th>sep_prob_mean</th>\n",
       "      <th>len_min</th>\n",
       "      <th>len_max</th>\n",
       "      <th>len_mean</th>\n",
       "      <th>token_probs_min</th>\n",
       "      <th>token_probs_max</th>\n",
       "      <th>token_probs_mean</th>\n",
       "      <th>bi_probs_min</th>\n",
       "      <th>bi_probs_max</th>\n",
       "      <th>bi_probs_mean</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>25.1000</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>25.1000</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.6976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>27.8889</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.6939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.8226</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>27.8889</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.6932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3092</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>27.8889</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>46.5000</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.4897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8320</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>34.2632</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>0.4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.7116</td>\n",
       "      <td>4</td>\n",
       "      <td>303</td>\n",
       "      <td>93.0000</td>\n",
       "      <td>0.7139</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.7409</td>\n",
       "      <td>4</td>\n",
       "      <td>355</td>\n",
       "      <td>93.0000</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>4</td>\n",
       "      <td>355</td>\n",
       "      <td>93.0000</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52598 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  fold  score  model  num_paras  num_words  num_gts  sep_prob_min  sep_prob_max  sep_prob_mean  len_min  len_max  len_mean  token_probs_min  token_probs_max  token_probs_mean  bi_probs_min  bi_probs_max  bi_probs_mean   pred\n",
       "0     0000D23A521A  0    0.5238  5      10         251        8       0.1773        0.9984        0.8401          13       65      25.1000   0.9856           1.0000           0.9976            0.0736        0.6168        0.3648         0.7073\n",
       "12    0000D23A521A  0    0.3429  12     10         251        8       0.5666        0.9988        0.8730          6        65      25.1000   0.5612           1.0000           0.9319            0.0001        0.6168        0.2826         0.6976\n",
       "10    0000D23A521A  0    0.5238  3      9          251        8       0.2271        0.9984        0.8453          13       65      27.8889   0.9998           1.0000           1.0000            0.0736        0.6168        0.3121         0.6939\n",
       "11    0000D23A521A  0    0.5238  13     9          251        8       0.1254        0.9982        0.8226          13       65      27.8889   0.9995           1.0000           0.9999            0.0736        0.6168        0.3121         0.6932\n",
       "7     0000D23A521A  0    0.4857  8      9          251        8       0.3092        0.9981        0.8506          13       65      27.8889   1.0000           1.0000           1.0000            0.0736        0.6168        0.3179         0.6902\n",
       "...            ... ..       ... ..     ..          ...       ..          ...           ...           ...          ..       ..          ...      ...              ...              ...               ...           ...           ...            ...\n",
       "8315  FFF1442D6698  0    0.5238  4      14         651        10      0.0002        0.9960        0.7836          1        182     46.5000   0.0580           1.0000           0.7189            0.0172        0.6168        0.2488         0.4897\n",
       "8320  FFF1442D6698  0    0.6653  8      19         651        10      0.0001        0.9926        0.7051          1        136     34.2632   0.0533           1.0000           0.7279            0.0172        0.6168        0.2689         0.4834\n",
       "8321  FFF1442D6698  0    0.4857  10     7          651        10      0.0288        0.9912        0.7116          4        303     93.0000   0.7139           1.0000           0.9591            0.0051        0.6168        0.2309         0.4354\n",
       "8314  FFF1442D6698  0    0.3333  2      7          651        10      0.0002        0.9966        0.7409          4        355     93.0000   0.7210           1.0000           0.9601            0.0736        0.6168        0.2456         0.3783\n",
       "8319  FFF1442D6698  0    0.3333  6      7          651        10      0.4618        0.9935        0.7635          4        355     93.0000   0.6921           1.0000           0.9266            0.0736        0.6168        0.2456         0.3715\n",
       "\n",
       "[52598 rows x 20 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>model</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8320</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52598 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  score  model   pred\n",
       "0     0000D23A521A 0.5238  5     0.7073\n",
       "12    0000D23A521A 0.3429  12    0.6976\n",
       "10    0000D23A521A 0.5238  3     0.6939\n",
       "11    0000D23A521A 0.5238  13    0.6932\n",
       "7     0000D23A521A 0.4857  8     0.6902\n",
       "...            ...    ... ..        ...\n",
       "8315  FFF1442D6698 0.5238  4     0.4897\n",
       "8320  FFF1442D6698 0.6653  8     0.4834\n",
       "8321  FFF1442D6698 0.4857  10    0.4354\n",
       "8314  FFF1442D6698 0.3333  2     0.3783\n",
       "8319  FFF1442D6698 0.3333  6     0.3715\n",
       "\n",
       "[52598 rows x 4 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalid[['id', 'score', 'model', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.6612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51559</th>\n",
       "      <td>001A03E06F3C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.8277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50505</th>\n",
       "      <td>004BE23B05BF</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.6418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49451</th>\n",
       "      <td>0054850878E3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.6393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48397</th>\n",
       "      <td>00852F390697</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4841</td>\n",
       "      <td>0.6911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12544</th>\n",
       "      <td>FF9114183593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11490</th>\n",
       "      <td>FF9DB9D43F72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10436</th>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9382</th>\n",
       "      <td>FFC43F453EF6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.7198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3094 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  model  score   pred\n",
       "15     0000D23A521A  0     0.4857 0.6612\n",
       "51559  001A03E06F3C  0     0.7333 0.8277\n",
       "50505  004BE23B05BF  0     0.9333 0.6418\n",
       "49451  0054850878E3  0     0.4800 0.6393\n",
       "48397  00852F390697  0     0.4841 0.6911\n",
       "...             ... ..        ...    ...\n",
       "12544  FF9114183593  0     0.8857 0.6626\n",
       "11490  FF9DB9D43F72  0     0.6000 0.7118\n",
       "10436  FFA381E58FC6  0     0.6250 0.6454\n",
       "9382   FFC43F453EF6  0     0.4667 0.5465\n",
       "8328   FFF1442D6698  0     0.8286 0.7198\n",
       "\n",
       "[3094 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalid[dvalid.model==0][['id', 'model', 'score', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001A03E06F3C</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.8395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004BE23B05BF</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0054850878E3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.6621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00852F390697</td>\n",
       "      <td>14</td>\n",
       "      <td>0.5397</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>FF9114183593</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.7180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>FF9DB9D43F72</td>\n",
       "      <td>13</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>FFA381E58FC6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>FFC43F453EF6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>13</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.7513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3094 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  model  score   pred\n",
       "0     0000D23A521A  5     0.5238 0.7073\n",
       "1     001A03E06F3C  2     0.7333 0.8395\n",
       "2     004BE23B05BF  13    0.9500 0.7154\n",
       "3     0054850878E3  7     0.3500 0.6621\n",
       "4     00852F390697  14    0.5397 0.7352\n",
       "...            ...  ..       ...    ...\n",
       "3089  FF9114183593  15    0.7429 0.7180\n",
       "3090  FF9DB9D43F72  13    0.5600 0.8124\n",
       "3091  FFA381E58FC6  5     0.6667 0.6709\n",
       "3092  FFC43F453EF6  8     0.3333 0.6783\n",
       "3093  FFF1442D6698  13    0.8286 0.7513\n",
       "\n",
       "[3094 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp[['id', 'model', 'score', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "fes = []\n",
    "scores = []\n",
    "for row1, row2 in zip(dvalid[dvalid.model==0].itertuples(), dp.itertuples()):\n",
    "  if row2.pred - row1.pred > 0.2:\n",
    "    scores.append(row2.score)\n",
    "  else:\n",
    "    scores.append(row1.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7122306057294542"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
